{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut test part of ILI series\n",
    "ili_file = pd.read_excel('C:/D/HUST/research_flu_forecast/data for coding/ILI_all.xlsx')\n",
    "test_ILI = {}\n",
    "test_ILI['Nori'] = ili_file['n_ili'].values[-187:]\n",
    "test_ILI['Sori'] = ili_file['s_ili'].values[-187:]\n",
    "test_weektag = ili_file['weektag'].values[-187:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list = [\"Nori\", \"Sori\"]\n",
    "model_list = ['SVR_Iter', 'SVR_Dir', 'SVR_MIMO', 'MLP_Iter', 'MLP_Dir','MLP_MIMO']\n",
    "R = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate each PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate each PWD\n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/\"\n",
    "pwd_save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "\n",
    "for series_name in series_list:\n",
    "    test_series = test_ILI[series_name]\n",
    "    if os.path.exists(pwd_save_path + \"/\" + series_name) == False:\n",
    "        os.makedirs(pwd_save_path + \"/\" + series_name)\n",
    "    \n",
    "    for model_name in model_list:\n",
    "        for H in range(2,11):\n",
    "            pwd_file_name = \"PWD_\" + series_name + \"_\" + model_name + \"_y\" +str(H) + \".xlsx\"\n",
    "            wr = pd.ExcelWriter(pwd_save_path + \"/\" + series_name + \"/\" + pwd_file_name)\n",
    "            col = ['outbreak1','outbreak2','outbreak3','outbreak_mean']\n",
    "            ind = ['step'+str(x+1) for x in range(H)]\n",
    "            ind.append('step_mean')\n",
    "            \n",
    "            for r in range(R):\n",
    "                file_name = series_name + \"_\" + model_name + \"_y\" +str(H) + \"_rank\" + str(r+1) + \".xlsx\"\n",
    "                result_file = pd.read_excel(open_path + series_name + \"/\" + model_name + \"/\"  + file_name, sheet_name = 'y_test_pred')\n",
    "                true_len = len(test_series)\n",
    "                pred_len = result_file.shape[0]\n",
    "                \n",
    "                #各step对齐到原序列的时间点\n",
    "                t_m = np.zeros((H+1,true_len))\n",
    "                t_m[H] = test_series\n",
    "                step_list = list(range(H))\n",
    "                step_list.reverse()                    #list.reverse()没有返回值，不返回新的反序list，只是对原list的元素进行反向排序\n",
    "                for step in step_list:           \n",
    "                    t_m[step][(step+1-H)-pred_len:true_len + (step+1-H)] = result_file['step'+ str(step+1)].values\n",
    "                            \n",
    "                #三个爆发期的切割点：100,155; 抛弃50前的小峰值部分\n",
    "                outbreaks = [t_m[:,50:100].copy(),t_m[:,100:155].copy(),t_m[:,155:].copy()]\n",
    "                pwd = np.zeros((H+1,3+1))\n",
    "                for n in range(3):\n",
    "                    pw_index = np.argmax(outbreaks[n], axis=1)\n",
    "                    for step in range(H):\n",
    "                         pwd[step,n] = abs(pw_index[H]-pw_index[step])   \n",
    "\n",
    "                #求均值\n",
    "                pwd[:,3] = np.mean(pwd[:,:3],axis=1)\n",
    "                pwd[H,:] = np.mean(pwd[:H,:],axis=0)\n",
    "                \n",
    "                pwd_df = pd.DataFrame(pwd,index = ind, columns = col)\n",
    "                pwd_df.to_excel(wr,'rank'+str(r+1))\n",
    "            wr.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PWD gather and averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWD averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD averaged\n",
    "#1)table(repeated experiment) averaged \n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/repeat average/\"\n",
    "for series_name in series_list:\n",
    "    for model_name in model_list:\n",
    "        save_name = \"repAve_PWD_\" + series_name + \"_\" + model_name + \".xlsx\"\n",
    "        wr1 = pd.ExcelWriter(save_path + save_name)\n",
    "        for H in range(2,11):\n",
    "            col = ['outbreak1','outbreak2','outbreak3','outbreak_mean']\n",
    "            ind = ['step'+str(x+1) for x in range(H)]\n",
    "            ind.append('step_mean')\n",
    "            \n",
    "            file_name = \"PWD_\" + series_name + \"_\" + model_name + \"_y\" +str(H) + \".xlsx\"\n",
    "            add_table = 0.0\n",
    "            for r in range(R):\n",
    "                add_table += pd.read_excel(open_path+series_name+ \"/\" + file_name,sheet_name = 'rank'+str(r+1)).values[:,1:]\n",
    "            mean_table = add_table/R\n",
    "            mean_df = pd.DataFrame(mean_table, index = ind, columns = col)\n",
    "            mean_df.to_excel(wr1,'H'+str(H))\n",
    "        wr1.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PWD total averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD averaged\n",
    "#2)total&outbreak averaged gather;first model then PWD_type\n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/repeat average/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "\n",
    "#pandas 多级索引 \n",
    "dual_ind_list = [['SVR_Iter', 'SVR_Dir', 'SVR_MIMO', 'MLP_Iter', 'MLP_Dir','MLP_MIMO'],['outbreak1','outbreak2','outbreak3','outbreak_ave']]\n",
    "pwd_ind = pd.MultiIndex.from_product(dual_ind_list,names = ['Model','PWD_type'])\n",
    "col= [\"H\"+str(h) for h in range(2,11)]\n",
    "\n",
    "wr2 = pd.ExcelWriter(save_path + \"PWD_total_ave_modelFirstCol.xlsx\")\n",
    "for series_name in series_list:\n",
    "    pwd_table = np.zeros((4*6,9))\n",
    "    for num_m,model_name in enumerate(model_list):\n",
    "        open_file = \"repAve_PWD_\" + series_name + \"_\" + model_name + \".xlsx\"\n",
    "        for H in range(2,11):\n",
    "            pwd_table[num_m*4:(num_m+1)*4, H-2] = pd.read_excel(open_path + open_file, sheet_name='H'+str(H)).values[H,1:]\n",
    "    pwd_df = pd.DataFrame(pwd_table,index = pwd_ind,columns=col)\n",
    "    pwd_df.to_excel(wr2,series_name)\n",
    "wr2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD averaged\n",
    "#2)total&outbreak averaged gather;first PWD_type then model \n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/repeat average/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "\n",
    "#pandas 多级索引 \n",
    "dual_ind_list = [['outbreak1','outbreak2','outbreak3','outbreak_ave'],['SVR_Iter', 'SVR_Dir', 'SVR_MIMO', 'MLP_Iter', 'MLP_Dir','MLP_MIMO']]\n",
    "pwd_ind = pd.MultiIndex.from_product(dual_ind_list,names = ['PWD_type','Model'])\n",
    "col= [\"H\"+str(h) for h in range(2,11)]\n",
    "\n",
    "wr2 = pd.ExcelWriter(save_path + \"PWD_total_ave.xlsx\")\n",
    "for series_name in series_list:\n",
    "    pwd_table = np.zeros((4*6,9))\n",
    "    for num_m,model_name in enumerate(model_list):\n",
    "        open_file = \"repAve_PWD_\" + series_name + \"_\" + model_name + \".xlsx\"\n",
    "        for H in range(2,11):\n",
    "            for ob_n in range(0,4):\n",
    "                pwd_table[num_m+(ob_n*6),H-2] = pd.read_excel(open_path + open_file, sheet_name='H'+str(H)).values[H,ob_n+1]\n",
    "    pwd_df = pd.DataFrame(pwd_table,index = pwd_ind,columns=col)\n",
    "    pwd_df.to_excel(wr2,series_name)\n",
    "wr2.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PWD step averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD step gather and averaged: first PWD_type then model \n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/repeat average/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "\n",
    "#pandas 多级索引 \n",
    "dual_ind_list = [['outbreak1','outbreak2','outbreak3','outbreak_ave'],['SVR_Iter', 'SVR_Dir', 'SVR_MIMO', 'MLP_Iter', 'MLP_Dir','MLP_MIMO']]\n",
    "pwd_ind = pd.MultiIndex.from_product(dual_ind_list,names = ['PWD_type','Model'])\n",
    "\n",
    "col_list = []\n",
    "for H in range(2,11):\n",
    "    for h in range(1,H+1):\n",
    "        col_list.append(['H'+str(H),'step'+str(h)])\n",
    "col_df = pd.DataFrame(col_list)\n",
    "col = pd.MultiIndex.from_frame(col_df,names = ['Horizon','Step'])\n",
    "\n",
    "wr3 = pd.ExcelWriter(save_path + \"PWD_step_ave.xlsx\")\n",
    "for series_name in series_list:\n",
    "    pwd_table = np.zeros((4*6,54))     #54：2+3+4+...+10\n",
    "    for num_m,model_name in enumerate(model_list):\n",
    "        open_file = \"repAve_PWD_\" + series_name + \"_\" + model_name + \".xlsx\"\n",
    "        \n",
    "        H_position = 0\n",
    "        for H in range(2,11):\n",
    "            for ob_n in range(0,4):\n",
    "                pwd_table[num_m+(ob_n*6),H_position:(H_position+H)] = pd.read_excel(open_path + open_file, sheet_name='H'+str(H)).values[0:H,ob_n+1]                \n",
    "            H_position += H\n",
    "            \n",
    "    pwd_df = pd.DataFrame(pwd_table,index = pwd_ind,columns=col)\n",
    "    pwd_df.to_excel(wr3,series_name)\n",
    "wr3.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWD gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total and outbreak gather\n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/PWD_gather/\"\n",
    "ob_sheet = ['Outbreak1','Outbreak2','Outbreak3','total']\n",
    "\n",
    "col = model_list\n",
    "ind = ['rank' + str(i+1) for i in range(R)]\n",
    "\n",
    "for series_name in series_list:\n",
    "    for H in range(2,11):\n",
    "        save_name = \"PWD_total_gather_\" + series_name + \"_H\" +str(H) + \".xlsx\"\n",
    "        wr1 = pd.ExcelWriter(save_path + save_name)\n",
    "        \n",
    "        for ob_n in range(0,4):\n",
    "            pwd_table = np.zeros((20,6))\n",
    "            \n",
    "            for m_n, model_name in enumerate(model_list):\n",
    "                open_name = \"PWD_\" + series_name + \"_\" + model_name + \"_y\" +str(H) + \".xlsx\"\n",
    "                \n",
    "                for r in range(R):\n",
    "                    pwd_table[r, m_n] = pd.read_excel(open_path + series_name+ \"/\" + open_name, sheet_name = 'rank'+str(r+1)).values[H, ob_n+1]\n",
    "        \n",
    "            pwd_df = pd.DataFrame(pwd_table, index = ind, columns = col)\n",
    "            pwd_df.to_excel(wr1,ob_sheet[ob_n])\n",
    "        wr1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only total gather\n",
    "open_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/PWD_gather/\"\n",
    "save_path = \"C:/D/HUST/research_flu_forecast/experiment/result/New/PWD/total_metric_gather/\"\n",
    "if os.path.exists(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for series_name in series_list:\n",
    "    save_name = series_name + \"_total_PWD_gather.xlsx\"\n",
    "    wr = pd.ExcelWriter(save_path +save_name)\n",
    "    \n",
    "    for H in range(2,11):\n",
    "        open_name = \"PWD_total_gather_\" + series_name + \"_H\" +str(H) + \".xlsx\"\n",
    "        total_df = pd.read_excel(open_path + open_name,sheet_name='total', index_col=0)\n",
    "        total_df.to_excel(wr,\"H\"+str(H))\n",
    "    wr.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
